---
title: "R Notebook"
output: html_notebook
---
1 MVP
1.1 Hypothesis testing - practical
You work for an animal conservation organisation and are looking to do some investigating into some of the animals to provide evidence for some projects you are looking to run.

In this homework we’ll use the msleep data set provided in the ggplot package. It concerns the sleeping patterns of various types of mammal.

library(tidyverse)
data(msleep)
Explore the dataset and familiarise yourself with it.

Jabberwockies sleep for around 7 hours a night, on average. Perform an appropriate statistical test to determine whether the mean sleep_total in the sampled population of animal types differs from the typical value for jabberwockies.

Perform an appropriate statistical test to determine whether omnivores sleep for significantly longer than herbivores, on average.

Perform an appropriate statistical test to determine whether the proportion of domesticated animal types in the population of animal types is greater than 5%.
[Hint - think about creating an is_domesticated variable for the analysis]

1.2 Hypothesis testing - interpretation
1.2.1 Defining the Hypothesis
For the following three business problems write out H0 and Ha in both mathematical notation and in words. Also state the method you would use to generate the null distribution (bootstrap, permutation or simulation).

You work for a independent coffee shop. The boss tells you that she thinks that around 40% of people in the town (population 30,000) know of the coffee shop, but you are skeptical of the estimate. You conduct a random survey of 200 people in the town, asking if respondents are aware of your coffee shop. You want to use the sample to test the hypothesis that 40% or more of the town’s population have heard of the coffee shop.

You work for a website design company and have performed an A/B test on the position of a banner on a website promoting a particular item.


A/B testing A method comparing two versions of a web page, email, flyer or other marketing device against each other to determine which version performs better. As it is essentially a controlled experiment, the design should try to ensure that the groups experiencing both versions of the marketing device are equivalent and representative of the population.



You selected five days at random last month and then randomly selected 200 of each sampled day’s users into group A and another 200 of that day’s users into group B. Group A continued to be shown the banner at the right hand side of the webpage (its usual position) while group B was shown the banner at the top of the page. You monitored each sampled user’s interactions with the website, in particular the ‘click through rate’ (CTR) on the banner, i.e. what proportion of sampled users clicked on the banner. You want to use the sampled data to test the hypothesis that website users overall are more likely to click on the banner if positioned at the top of the page

You work as an analyst for a car manufacturing company - they have specific standards they must meet for standards and regulation purposes. You have been asked to check the quality control of the manufacture of a particular car part. You have been given data on a sample of 200 parts produced over the period of a week (the sampled parts were pulled at random from the production line and measured: the factory produced a lot more than 200 parts that week). The specification of the part stipulates a width of 145mm, and the manufacturing process is said to have ‘drifted’ if the mean width of parts differs significantly from 145mm. You want to use the sampled measurements to test whether the process overall has drifted.

1.2.2 Interpreting the results
For the 3 business problems stated above, imagine we performed you got the following p-values (with the given significance levels) write out your interpretation of the results.

Coffee shop problem. Significance level: 0.05, calculated p-value: 0.07

Website company problem. Significance level: 0.01, p-value: 0.006

Manufacturing company problem. Significance level: 0.05, p-value: 0.55

2 Extension
2.1 Market Basket Analysis
Association rule mining is regularly used by retailers to find associations between products that people purchase, perhaps for an online retailer, the items that people put together in their ‘baskets’, and in a bricks and mortar retailer, the items purchased together in a single transaction. The aim is to find recurring patterns in the transactions which the retailer can then use to do targeted marketing of items, seeking to increase ‘cross sales’. Rules mining of this sort can also be used in other industries beyond retail to identify patterns in data.

Market basket analysis (MBA) uses association rule mining. It looks at the association of items occurring in a single basket, and so won’t look at your purchases over time, but only items that are purchased together in a single purchase (i.e. a ‘basket’). As a good example, you may have seen the ‘Frequently Bought Together’ section on Amazon (and other sites), which looks at items you’ve got in your basket and suggests items that other people commonly have in their baskets when they also have these items:



MBA differs from recommendation algorithms because the association rules look only at items bought together in a single purchase, they don’t use any characteristics of the purchaser to profile them (e.g. ‘Based on purchases by people like you, you may also like…’) or how their purchases vary over time. The association rules used for MBA use the probability principles we learned on Monday this week.

2.2 Association rules
The rules obtained by MBA have three concepts associated with them, as follows:

Support
The probability of items in the rule being purchased together:

e.g. sup(A→B)=P(A and B being purchased together)=number of transactions involving A and Btotal number of transactions

Support also has meaning for single items:

e.g. sup(A)=P(A)=number of transactions involving Atotal number of transactions

Confidence
The proportion of purchases of A where B has also been purchased:

e.g. conf(A→B)=P(A and B being purchased together)P(A being purchased)

Lift
Increase in sales of A when sold with B

lift(A→B)=sup(A→B)sup(A)×sup(B)

If sup(A→B)=sup(A)×sup(B) then this means P(A and B)=P(A)×P(B). We know from the probability lesson earlier in the week that this means the purchase of A and B are independent events. This may help with our interpretation of lift values:

lift(A→B)>1 - items A and B are more likely to be bought together
lift(A→B)=1 - no correlation between items A and B being bought together
lift(A→B)<1 - items A and B are unlikely to be bought together
A and B don’t need to be single items, they could be sets of items (itemsets) e.g. A = {TV, DVD player}, B = {TV stand}.

2.3 Using the rules
Once we have calculated the rules we can use them to gain insights about items/itemsets.

For example, if for items A and B the corresponding rule (A→B) has a low support but a lift greater than 1 then we can say that when A is purchased B is often purchased with it (high lift), but such transactions don’t happen all that frequently (low support).

The apriori algorithm is often used as a way of selecting ‘interesting’ rules. It will calculate all the support, confidence and lift values for the item/itemset combinations of your dataset and will return those with support values greater than a pre-defined threshold value set by the user.

2.4 Homework exercise
Let’s load in some transaction data which has details on the items purchased in each transaction (where each transaction is uniquely identified by the InvoiceNo variable).

library(tidyverse)
transactions <- read_csv("data/online_retail_subset.csv")
## Parsed with column specification:
## cols(
##   InvoiceNo = col_character(),
##   StockCode = col_character(),
##   Description = col_character(),
##   InvoiceDate = col_character(),
##   UnitPrice = col_double(),
##   CustomerID = col_double(),
##   Country = col_character()
## )
head(transactions, 20)
InvoiceNo
<chr>
StockCode
<chr>
Description
<chr>
InvoiceDate
<chr>
UnitPrice
<dbl>
536365	85123A	WHITE HANGING HEART T-LIGHT HOLDER	12/1/10 8:26	2.55	
536365	71053	WHITE METAL LANTERN	12/1/10 8:26	3.39	
536365	84406B	CREAM CUPID HEARTS COAT HANGER	12/1/10 8:26	2.75	
536365	84029G	KNITTED UNION FLAG HOT WATER BOTTLE	12/1/10 8:26	3.39	
536365	84029E	RED WOOLLY HOTTIE WHITE HEART.	12/1/10 8:26	3.39	
536365	22752	SET 7 BABUSHKA NESTING BOXES	12/1/10 8:26	7.65	
536365	21730	GLASS STAR FROSTED T-LIGHT HOLDER	12/1/10 8:26	4.25	
536366	22633	HAND WARMER UNION JACK	12/1/10 8:28	1.85	
536366	22632	HAND WARMER RED POLKA DOT	12/1/10 8:28	1.85	
536367	84879	ASSORTED COLOUR BIRD ORNAMENT	12/1/10 8:34	1.69	
1-10 of 20 rows | 1-5 of 7 columns
2.5 Association rules
For the first section we are interested in the purchase of two particular items:

item A - ‘HEART OF WICKER SMALL’ (StockCode 22469)
item B - ‘LARGE CAKE TOWEL PINK SPOTS’ (StockCode 21110)
Calculate the support for item A (this will be the support for a single item)

Calculate the support and confidence for rule (A→B).

Calculate the lift for (A→B)

[Hint - you will need to calculate the support for B]

2.6 Apriori algorithm
Read up on the arules and arulesViz packages, which make use of the ‘apriori’ algorithm http://www.salemmarafi.com/code/market-basket-analysis-with-r/comment-page-1/

Use these packages to play around, applying the apriori algorithm to the transactions dataset we have.

To use the arules package we need the data to be a special type of ‘transactions’ object. We do this by reading in the data using read.transactions() function from the arules package. We have done this for you below (for more information on this type of transactions object see the helpfile ?transactions):

library(arules)
library(arulesViz)
transactions_reformat <- transactions %>%
  select(InvoiceNo, Description) %>%
  na.omit()

write_csv(transactions_reformat, "transactions_reformat.csv")

apriori_format <- read.transactions("transactions_reformat.csv", format = "single", sep = ",", header = TRUE, cols = c("InvoiceNo", "Description"))
## Warning in scan(file = file, sep = sep, quote = quote, what = what, flush =
## TRUE, : EOF within quoted string
inspect(head(apriori_format))
##     items                                                       transactionID
## [1] {CREAM CUPID HEARTS COAT HANGER,                                         
##      GLASS STAR FROSTED T-LIGHT HOLDER,                                      
##      KNITTED UNION FLAG HOT WATER BOTTLE,                                    
##      RED WOOLLY HOTTIE WHITE HEART.,                                         
##      SET 7 BABUSHKA NESTING BOXES,                                           
##      WHITE HANGING HEART T-LIGHT HOLDER,                                     
##      WHITE METAL LANTERN}                                              536365
## [2] {HAND WARMER RED POLKA DOT,                                              
##      HAND WARMER UNION JACK}                                           536366
## [3] {ASSORTED COLOUR BIRD ORNAMENT,                                          
##      BOX OF 6 ASSORTED COLOUR TEASPOONS,                                     
##      BOX OF VINTAGE ALPHABET BLOCKS,                                         
##      BOX OF VINTAGE JIGSAW BLOCKS,                                           
##      DOORMAT NEW ENGLAND,                                                    
##      FELTCRAFT PRINCESS CHARLOTTE DOLL,                                      
##      HOME BUILDING BLOCK WORD,                                               
##      IVORY KNITTED MUG COSY,                                                 
##      LOVE BUILDING BLOCK WORD,                                               
##      POPPYS PLAYHOUSE BEDROOM
## 536367,POPPYS PLAYHOUSE KITCHEN,              
##      RECIPE BOX WITH METAL HEART}                                      536367
## [4] {BLUE COAT RACK PARIS FASHION,                                           
##      JAM MAKING SET WITH JARS,                                               
##      RED COAT RACK PARIS FASHION,                                            
##      YELLOW COAT RACK PARIS FASHION}                                   536368
## [5] {BATH BUILDING BLOCK WORD}                                         536369
## [6] {ALARM CLOCK BAKELIKE GREEN,                                             
##      ALARM CLOCK BAKELIKE PINK,                                              
##      ALARM CLOCK BAKELIKE RED,                                               
##      CHARLOTTE BAG DOLLY GIRL DESIGN,                                        
##      CIRCUS PARADE LUNCH BOX,                                                
##      INFLATABLE POLITICAL GLOBE,                                             
##      LUNCH BOX I LOVE LONDON,                                                
##      MINI JIGSAW CIRCUS PARADE,                                              
##      MINI JIGSAW SPACEBOY,                                                   
##      MINI PAINT SET VINTAGE,                                                 
##      PANDA AND BUNNIES STICKER SHEET,                                        
##      POSTAGE,                                                                
##      RED TOADSTOOL LED NIGHT LIGHT,                                          
##      ROUND SNACK BOXES SET OF4 WOODLAND,                                     
##      SET 2 TEA TOWELS I LOVE LONDON,                                         
##      SET/2 RED RETROSPOT TEA TOWELS,                                         
##      SPACEBOY LUNCH BOX,                                                     
##      STARS GIFT TAPE,                                                        
##      VINTAGE HEADS AND TAILS CARD GAME,                                      
##      VINTAGE SEASIDE JIGSAW PUZZLES}                                   536370
Now you’re all set to play around with arules and arulesViz.

Warning about run time/memory usage: if the minimum support is set too low for the dataset, then the algorithm will try to create an extremely large set of itemsets/rules. This will result in very long run times and the process may eventually run out of memory. You can either start by trying a reasonably high support (for this dataset, we would suggest starting at 1 and then systematically lower the support if don’t see any results). There is also an argument maxtime which can be used to prevent long run times (more information on that in the apriori user document here).

